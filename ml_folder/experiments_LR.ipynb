{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7aed2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 14:52:25.142267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-21 14:52:25.142283: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 14:52:26.266251: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-06-21 14:52:26.266291: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: kamal-Inspiron-3593\n",
      "2024-06-21 14:52:26.266296: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: kamal-Inspiron-3593\n",
      "2024-06-21 14:52:26.266417: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.171.4\n",
      "2024-06-21 14:52:26.266441: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.171.4\n",
      "2024-06-21 14:52:26.266445: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.171.4\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell # type: ignore\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "from ML import *\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "print(\"GPU is\",\"avaliable\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWe first import the necessary libraries and LOAD all the data for training and testing. Such data corresponds to the original samples from DeltaPhish (either benign or malicious) as well as the 100 phishing samples (not used in the training data) that we use as basis to create our adversarial examples.\\n\\nWe then develop a given leaner (i.e., a phishing detector) by using the train data and a Logistic Regression algorithm, and test it on the test data, computing the FPR and TPR shown in Table 3; we also compute the TPR on the subset of 100 samples used for our adversarial evaluations, which correspond to the results in Figure 4b (for the LR algorithm).\\n\\nWe then proceed to assess the robustness of the detector against ALL the 12 attacks considered in our paper, all of which use the 100 samples as basis. For WA and WA+, we already provide the preprocessed version. For PA, we use the samples created during the preprocessing phase. For MA, we create the samples at runtime.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "We first import the necessary libraries and LOAD all the data for training and testing. Such data corresponds to the original samples from DeltaPhish (either benign or malicious) as well as the 100 phishing samples (not used in the training data) that we use as basis to create our adversarial examples.\n",
    "\n",
    "We then develop a given leaner (i.e., a phishing detector) by using the train data and a Logistic Regression algorithm, and test it on the test data, computing the FPR and TPR shown in Table 3; we also compute the TPR on the subset of 100 samples used for our adversarial evaluations, which correspond to the results in Figure 4b (for the LR algorithm).\n",
    "\n",
    "We then proceed to assess the robustness of the detector against ALL the 12 attacks considered in our paper, all of which use the 100 samples as basis. For WA and WA+, we already provide the preprocessed version. For PA, we use the samples created during the preprocessing phase. For MA, we create the samples at runtime.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356c3d1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The code starts by loading a JSON file containing the dataset using a custom data_load function. \n",
    "# This dataset (data_delta) includes features relevant to phishing detection.\n",
    "json_file='../data_folder/deltaphish/preprocessed/normal/deltaphish_total_feature_modified.json'\n",
    "data_delta=data_load(json_file)\n",
    "\n",
    "\n",
    "# remove evasion dataset, then build new PWDs using remain data\n",
    "# It loads a preprocessed dataset containing 100 samples of phishing data from a pickle file using joblib.\n",
    "phish_sub_test_x=joblib.load('../data_folder/deltaphish/preprocessed/phish_sub_test_x_100.pkl')\n",
    "#print('phish_test_x index',phish_sub_test_x.index)#100\n",
    "#print('phish_sub_test_x shape',phish_sub_test_x.shape)\n",
    "\n",
    "\n",
    "# The code creates a copy of the original dataset (data_delta_change) to manipulate it without altering the original data.\n",
    "data_delta_change=data_delta.copy()\n",
    "\n",
    "#get the 100 phish samples and add them to the test dataset\n",
    "phish_sub_test_later=data_delta_change.loc[phish_sub_test_x.index].copy()\n",
    "data_delta_change=data_delta_change.drop(phish_sub_test_x.index)# del those 100 samples\n",
    "\n",
    "\n",
    "# The code splits the remaining data (data_delta_change) into training and test sets using train_test_split. \n",
    "# It sets a fixed training size of 3200 samples and a test size of 700 samples.\n",
    "# Features (train_x0) and labels (train_y0) for the training set are separated, with features consisting of the first 58 columns and labels being the 59th column.\n",
    "train_random,test_random=train_test_split(data_delta_change,train_size=3200,test_size=700,shuffle=True,random_state=11)\n",
    "train_x0=train_random.iloc[:,0:58]\n",
    "train_y0=train_random.iloc[:,58]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The code combines the initially separated test data (test_random) with the phishing sub test data (phish_sub_test_later).\n",
    "# Features (test_x0) and labels (test_y0) for the combined test set are separated similarly to the training set.\n",
    "#test_later=pd.concat(test_random,phish_sub_test_later)\n",
    "frames =[test_random,phish_sub_test_later]\n",
    "test_later=pd.concat(frames)\n",
    "test_x0=test_later.iloc[:,0:58] \n",
    "test_y0=test_later.iloc[:,58] \n",
    "\n",
    "\n",
    "# The code extracts HTML-related features (columns 27 to 49) for both training and test sets.\n",
    "# It also extracts URL-related features (columns 0 to 27 and 49 to 58) for both training and test sets.\n",
    "# The labels for these subsets are set to the same values as train_y0 and test_y0\n",
    "#use only html features\n",
    "train_html_x0=train_random.iloc[:,27:49]\n",
    "test_html_x0=test_later.iloc[:,27:49]\n",
    "#only url features\n",
    "train_url_x0=pd.concat([train_random.iloc[:,0:27],train_random.iloc[:,49:58]],axis=1)\n",
    "test_url_x0=pd.concat([test_later.iloc[:,0:27],test_later.iloc[:,49:58]],axis=1)\n",
    "train_y1=train_url_y0=train_html_y0=train_y0\n",
    "test_y1=test_url_y0=test_html_y0=test_y0\n",
    "\n",
    "\n",
    "# The code identifies indices of benign and phishing samples in the test data.\n",
    "benign_index=test_y0[test_y0==0].index.tolist()#\n",
    "phish_index=test_y0[test_y0==1].index.tolist()#\n",
    "\n",
    "#generate benign_test_x_y\n",
    "# It creates separate datasets for benign samples (benign_test_x and benign_test_y) and phishing samples (phish_sub_test_y).\n",
    "# It extracts HTML and URL features for these benign and phishing test datasets.\n",
    "benign_test_x=test_x0.loc[benign_index,:]\n",
    "benign_test_y= test_y0.loc[benign_index]# \n",
    "benign_test_url_x=pd.concat([benign_test_x.iloc[:,0:27],benign_test_x.iloc[:,49:58]],axis=1)\n",
    "benign_test_html_x=benign_test_x.iloc[:,27:49]\n",
    "\n",
    "phish_sub_test_y=test_y0[phish_sub_test_x.index]#100 phishing samples\n",
    "phish_sub_test_html_x=phish_sub_test_x.iloc[:,27:49]\n",
    "phish_sub_test_url_x=pd.concat([phish_sub_test_x.iloc[:,0:27],phish_sub_test_x.iloc[:,49:58]],axis=1)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d2cbb4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Baseline Performance- refer to Table 4, bottom row. No Attack and no Evasion space involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a66b9d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR Values\n",
      "Fc:\n",
      "recall 0.84\n",
      "Fu:\n",
      "recall 0.26\n",
      "Fr:\n",
      "recall 0.77\n",
      "\n",
      "\n",
      "\n",
      "FPR Values\n",
      "Fc:\n",
      "fpr 0.010\n",
      "Fu:\n",
      "fpr 0.010\n",
      "Fr:\n",
      "fpr 0.020\n"
     ]
    }
   ],
   "source": [
    "# The code sets a fixed random state for reproducibility. Using a consistent random state ensures that the results can be replicated.\n",
    "random_state = 42\n",
    "# Setting the seed for numpy-generated random numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setting the seed for Python's built-in random module\n",
    "random.seed(42)\n",
    "\n",
    "# Setting the seed for TensorFlow if used\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Three logistic regression models are initialized with the following parameters:\n",
    "# max_iter=1000: Allows the model to run for up to 1000 iterations to ensure convergence.\n",
    "# solver='liblinear': Uses the 'liblinear' solver, which is efficient for small datasets.\n",
    "# penalty='l1': Applies L1 regularization to encourage sparsity in the model coefficients.\n",
    "# random_state=random_state: Ensures reproducibility by setting a fixed random state.\n",
    "model_lr_0 = LogisticRegression(max_iter=1000,solver='liblinear',penalty='l1', random_state=random_state) \n",
    "model_lr_1 = LogisticRegression(max_iter=1000,solver='liblinear',penalty='l1', random_state=random_state) \n",
    "model_lr_2 = LogisticRegression(max_iter=1000,solver='liblinear',penalty='l1', random_state=random_state) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The rfe_get_score function is used to perform RFE on each model:\n",
    "# For model_lr_com, 41 features are selected from the combined feature set.\n",
    "# For model_lr_url, 26 features are selected from the URL feature set.\n",
    "# For model_lr_html, 15 features are selected from the HTML feature set.\n",
    "# The function returns the trained model, average FPR, FPR standard deviation, recall, recall standard deviation, time taken for RFE, and the RFE selector object\n",
    "model_lr_com,fpr_ave_com_lr,fpr_std_com_lr,recall_com_lr,re_std_com_lr,time1_com_lr,rfe_selector_lr_com =rfe_get_score(model_lr_0,41,train_x0,train_y0,test_x0,test_y0)\n",
    "model_lr_url,fpr_ave_url_lr,fpr_std_url_lr,recall_url_lr,re_std_url_lr,time1_url_lr,rfe_selector_lr_url=rfe_get_score(model_lr_1,26,train_url_x0,train_url_y0,test_url_x0,test_url_y0)\n",
    "model_lr_html,fpr_ave_html_lr,fpr_std_html_lr,recall_html_lr,re_std_html_lr,time1_html_lr,rfe_selector_lr_html=rfe_get_score(model_lr_2,15,train_html_x0,train_html_y0,test_html_x0,test_html_y0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The get_sub_base_rf_recall function calculates the recall for each model using the selected features.\n",
    "# It prints the recall values (TPR) for the combined (Fc), URL (Fu), and HTML (Fr) feature sets.\n",
    "print(\"TPR Values\")\n",
    "print('Fc:')\n",
    "lr_com_recall_whole=get_sub_base_rf_recall(model_lr_com,test_x0,test_y0,rfe_selector_lr_com)\n",
    "print('Fu:')\n",
    "lr_url_recall_whole=get_sub_base_rf_recall(model_lr_url,test_url_x0,test_url_y0,rfe_selector_lr_url)\n",
    "print('Fr:')\n",
    "lr_html_recall_whole=get_sub_base_rf_recall(model_lr_html,test_html_x0,test_html_y0,rfe_selector_lr_html)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The get_base_rf_fpr function calculates the FPR for each model using the selected features.\n",
    "# It prints the FPR values for the combined (Fc), URL (Fu), and HTML (Fr) feature sets.\n",
    "print(\"FPR Values\")\n",
    "print('Fc:' )\n",
    "base_lf_fpr_com=get_base_rf_fpr(model_lr_com,benign_test_x,benign_test_y,rfe_selector_lr_com)\n",
    "print('Fu:')\n",
    "base_lr_fpr_url=get_base_rf_fpr(model_lr_url,benign_test_url_x,benign_test_y,rfe_selector_lr_url)\n",
    "print('Fr:')\n",
    "base_lr_fpr_html=get_base_rf_fpr(model_lr_html,benign_test_html_x,benign_test_y,rfe_selector_lr_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d3b9d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# No attack for WA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b124c9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_no-atk_recall_Fc:\n",
      "recall 0.87\n",
      "lr_no-atk_recall_Fu:\n",
      "recall 0.32\n",
      "lr_no-atk_recall_Fr:\n",
      "recall 0.79\n"
     ]
    }
   ],
   "source": [
    "# It calls the get_sub_base_rf_recall function to calculate the recall (true positive rate) for the combined feature set model (model_lr_com) \n",
    "# on the phishing sub-test dataset (phish_sub_test_x and phish_sub_test_y).\n",
    "# The rfe_selector_lr_com is used to ensure the recall is calculated using the selected features from RFE.\n",
    "print('lr_no-atk_recall_Fc:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,phish_sub_test_x,phish_sub_test_y,rfe_selector_lr_com)\n",
    "\n",
    "\n",
    "\n",
    "# It calls the get_sub_base_rf_recall function to calculate the recall for the URL feature set model (model_lr_url) \n",
    "# on the phishing sub-test dataset (phish_sub_test_url_x and phish_sub_test_y).\n",
    "# The rfe_selector_lr_url is used to ensure the recall is calculated using the selected features from RFE.\n",
    "print('lr_no-atk_recall_Fu:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,phish_sub_test_url_x,phish_sub_test_y,rfe_selector_lr_url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# It calls the get_sub_base_rf_recall function to calculate the recall for the HTML feature set model (model_lr_html) \n",
    "# on the phishing sub-test dataset (phish_sub_test_html_x and phish_sub_test_y).\n",
    "# The rfe_selector_lr_html is used to ensure the recall is calculated using the selected features from RFE.\n",
    "print('lr_no-atk_recall_Fr:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,phish_sub_test_html_x,phish_sub_test_y,rfe_selector_lr_html)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2c191",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# wa_u attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2989841b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_recall_combined_wa_Fu:\n",
      "recall 0.58\n",
      "lr_recall_url_wa_Fu:\n",
      "recall 0.00\n",
      "lr_recall_html_wa_Fu:\n",
      "recall 0.79\n"
     ]
    }
   ],
   "source": [
    "# data_load: It loads data from a JSON file and returns it as a pandas DataFrame.\n",
    "# ad_url_problem_data: This variable stores the DataFrame loaded from the specified JSON file. \n",
    "# The file path contains a subset of phishing data specifically related to URLs.\n",
    "ad_url_problem_data=data_load(\"../data_folder/deltaphish/preprocessed/wa/wa_u/phish_sub_problem_space_url_shorten100.json\")\n",
    "\n",
    "\n",
    "# ad_url_problem_test_x: It extracts all columns from index 0 to 57 (58 columns in total), representing the features of the dataset.\n",
    "# ad_url_problem_test_y: It extracts the column at index 58, representing the labels (e.g., phishing or benign).\n",
    "ad_url_problem_test_x=ad_url_problem_data.iloc[:,0:58]\n",
    "ad_url_problem_test_y=ad_url_problem_data.iloc[:,58]\n",
    "\n",
    "\n",
    "#important to normalization \n",
    "# ad_url_problem_test_url_x: It concatenates columns 0 to 26 and columns 49 to 57 from the ad_url_problem_data DataFrame.\n",
    "# ad_url_problem_test_html_x: This variable stores the HTML features, extracted from columns 27 to 48 of the DataFrame. \n",
    "ad_url_problem_test_url_x=pd.concat([ad_url_problem_data.iloc[:,0:27],ad_url_problem_data.iloc[:,49:58]],axis=1)\n",
    "ad_url_problem_test_html_x=ad_url_problem_data.iloc[:,27:49]\n",
    "\n",
    "\n",
    "# lr_recall_combined_wa_u: This calculates the recall for the logistic regression model (model_lr_com) using the combined feature set (ad_url_problem_test_x). \n",
    "# The rfe_selector_lr_com is used to ensure the model uses the selected features.\n",
    "\n",
    "# lr_recall_url_wa_u: This calculates the recall for the logistic regression model (model_lr_url) using the URL feature set (ad_url_problem_test_url_x). \n",
    "# The rfe_selector_lr_url is used to ensure the model uses the selected features.\n",
    "\n",
    "# lr_recall_html_wa_u: This calculates the recall for the logistic regression model (model_lr_html) using the HTML feature set (ad_url_problem_test_html_x). \n",
    "# The rfe_selector_lr_html is used to ensure the model uses the selected features.\n",
    "print('lr_recall_combined_wa_Fu:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,ad_url_problem_test_x,ad_url_problem_test_y,rfe_selector_lr_com)\n",
    "print('lr_recall_url_wa_Fu:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,ad_url_problem_test_url_x,ad_url_problem_test_y,rfe_selector_lr_url)\n",
    "print('lr_recall_html_wa_Fu:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,ad_url_problem_test_html_x,ad_url_problem_test_y,rfe_selector_lr_html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e715bbc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# wa_r attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f6c704e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_wa_r_recall_combined:\n",
      "recall 0.78\n",
      "lr_wa_r_recall_url:\n",
      "recall 0.32\n",
      "lr_wa_r_recall_html:\n",
      "recall 0.60\n"
     ]
    }
   ],
   "source": [
    "# data_load: This function loads data from a specified JSON file and returns it as a pandas DataFrame.\n",
    "# ad_problem_data: Stores the DataFrame loaded from the specified JSON file.\n",
    "ad_problem_data=data_load(\"../data_folder/deltaphish/preprocessed/wa/wa_r/phish_sub_problem_space_html_add50internallinks.json\")#wa_u,wa_c\n",
    "\n",
    "\n",
    "# ad_problem_test_x: Stores the feature matrix extracted from the DataFrame. \n",
    "# It includes all columns from index 0 to 57 (58 columns in total), representing the features of the dataset.\n",
    "# ad_problem_test_y: Stores the target labels extracted from the DataFrame. It includes the column at index 58, representing the labels (e.g., phishing or benign).\n",
    "ad_problem_test_x=ad_problem_data.iloc[:,0:58]\n",
    "ad_problem_test_y=ad_problem_data.iloc[:,58]\n",
    "\n",
    "\n",
    "# ad_problem_test_url_x: Stores the URL features by concatenating columns 0 to 26 and columns 49 to 57 from the ad_problem_data DataFrame.\n",
    "# ad_problem_test_html_x: Stores the HTML features extracted from columns 27 to 48 of the DataFrame.\n",
    "ad_problem_test_url_x=pd.concat([ad_problem_data.iloc[:,0:27],ad_problem_data.iloc[:,49:58]],axis=1)\n",
    "ad_problem_test_html_x=ad_problem_data.iloc[:,27:49]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Recall Calculation: The function get_sub_base_rf_recall calculates the recall for each logistic regression model using the different feature sets (combined, URL, and HTML).\n",
    "# Combined Features: The recall is calculated for the model model_lr_com using the combined feature set (ad_problem_test_x).\n",
    "# URL Features: The recall is calculated for the model model_lr_url using the URL feature set (ad_problem_test_url_x).\n",
    "# HTML Features: The recall is calculated for the model model_lr_html using the HTML feature set (ad_problem_test_html_x).\n",
    "print('lr_wa_r_recall_combined:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,ad_problem_test_x,ad_problem_test_y,rfe_selector_lr_com)\n",
    "print('lr_wa_r_recall_url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,ad_problem_test_url_x,ad_problem_test_y,rfe_selector_lr_url)\n",
    "print('lr_wa_r_recall_html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,ad_problem_test_html_x,ad_problem_test_y,rfe_selector_lr_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17434d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# wa_c attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "106e09fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_wa_c_recall_combined:\n",
      "recall 0.44\n",
      "lr_wa_c_recall-url:\n",
      "recall 0.00\n",
      "lr_wa_c_recall-html:\n",
      "recall 0.59\n"
     ]
    }
   ],
   "source": [
    "# data_load: This function is assumed to be defined earlier and it loads data from a specified JSON file into a pandas DataFrame.\n",
    "ad_problem_data=data_load(\"../data_folder/deltaphish/preprocessed/wa/wa_c/phish_sub_problem_space_html_add50internallinks_combined_shorten_url.json\")\n",
    "\n",
    "\n",
    "# ad_problem_test_x: Stores the feature matrix extracted from the DataFrame, which includes columns 0 to 57 (58 columns in total).\n",
    "# ad_problem_test_y: Stores the target labels extracted from the DataFrame, which is the column at index 58.\n",
    "ad_problem_test_x=ad_problem_data.iloc[:,0:58]\n",
    "ad_problem_test_y=ad_problem_data.iloc[:,58]\n",
    " \n",
    "\n",
    "# ad_problem_test_url_x: Stores the URL features by concatenating columns 0 to 26 and columns 49 to 57 from the ad_problem_data DataFrame.\n",
    "# ad_problem_test_html_x: Stores the HTML features extracted from columns 27 to 48 of the DataFrame.\n",
    "ad_problem_test_url_x=pd.concat([ad_problem_data.iloc[:,0:27],ad_problem_data.iloc[:,49:58]],axis=1)\n",
    "ad_problem_test_html_x=ad_problem_data.iloc[:,27:49]\n",
    "\n",
    "\n",
    "print('lr_wa_c_recall_combined:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,ad_problem_test_x,ad_problem_test_y,rfe_selector_lr_com)\n",
    "print('lr_wa_c_recall-url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,ad_problem_test_url_x,ad_problem_test_y,rfe_selector_lr_url)\n",
    "print('lr_wa_c_recall-html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,ad_problem_test_html_x,ad_problem_test_y,rfe_selector_lr_html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46371bce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# wa+_u attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b48ffc8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_wa+_u_recall_combined:\n",
      "recall 0.82\n",
      "lr_wa+_u_recall-url:\n",
      "recall 0.00\n",
      "lr_wa+_u_recall-html:\n",
      "recall 0.79\n"
     ]
    }
   ],
   "source": [
    "# data_load: This function loads data from a specified JSON file into a pandas DataFrame.\n",
    "ad_problem_data=data_load(\"../data_folder/deltaphish/preprocessed/wa+/wa+_u/phish_sub_html_change_full_knowledge_change_again_later_only_url_shorten.json\")\n",
    "\n",
    "\n",
    "# ad_problem_test_x: Stores the feature matrix extracted from the DataFrame, which includes columns 0 to 57 (58 columns in total).\n",
    "# ad_problem_test_y: Stores the target labels extracted from the DataFrame, which is the column at index 58.\n",
    "ad_problem_test_x=ad_problem_data.iloc[:,0:58]\n",
    "ad_problem_test_y=ad_problem_data.iloc[:,58]\n",
    "\n",
    "\n",
    "# ad_problem_test_url_x: Stores the URL features by concatenating columns 0 to 26 and columns 49 to 57 from the ad_problem_data DataFrame.\n",
    "# ad_problem_test_html_x: Stores the HTML features extracted from columns 27 to 48 of the DataFrame.\n",
    "ad_problem_test_url_x=pd.concat([ad_problem_data.iloc[:,0:27],ad_problem_data.iloc[:,49:58]],axis=1)\n",
    "ad_problem_test_html_x=ad_problem_data.iloc[:,27:49]\n",
    "\n",
    "print('lr_wa+_u_recall_combined:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,ad_problem_test_x,ad_problem_test_y,rfe_selector_lr_com)\n",
    "print('lr_wa+_u_recall-url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,ad_problem_test_url_x,ad_problem_test_y,rfe_selector_lr_url)\n",
    "print('lr_wa+_u_recall-html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,ad_problem_test_html_x,ad_problem_test_y,rfe_selector_lr_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cfa86",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# wa+_r attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c02133dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_sub_baseline_recall_combined:\n",
      "recall 0.72\n",
      "lr_sub_baseline_recall-url:\n",
      "recall 0.32\n",
      "lr_sub_baseline_recall-html:\n",
      "recall 0.62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ad_problem_data=data_load(\"../data_folder/deltaphish/preprocessed/wa+/wa+_r/phish_sub_problem_space__full_onlyhtml_316.json\")#wa+_u,wa+_c\n",
    "\n",
    "ad_problem_test_x=ad_problem_data.iloc[:,0:58]\n",
    "ad_problem_test_y=ad_problem_data.iloc[:,58]\n",
    "\n",
    "ad_problem_test_url_x=pd.concat([ad_problem_data.iloc[:,0:27],ad_problem_data.iloc[:,49:58]],axis=1)\n",
    "ad_problem_test_html_x=ad_problem_data.iloc[:,27:49]\n",
    " \n",
    "print('lr_sub_baseline_recall_combined:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,ad_problem_test_x,ad_problem_test_y,rfe_selector_lr_com)\n",
    "print('lr_sub_baseline_recall-url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,ad_problem_test_url_x,ad_problem_test_y,rfe_selector_lr_url)\n",
    "print('lr_sub_baseline_recall-html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,ad_problem_test_html_x,ad_problem_test_y,rfe_selector_lr_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8eff3c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# wa+_c attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b947d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_wa+_c_recall_combined:\n",
      "recall 0.74\n",
      "lr_wa+_c_recall-url:\n",
      "recall 0.00\n",
      "lr_wa+_c_recall-html:\n",
      "recall 0.66\n"
     ]
    }
   ],
   "source": [
    "ad_problem_data=data_load(\"../data_folder/deltaphish/preprocessed/wa+/wa+_c/phish_sub_problem_space_mix_url_html_316.json\")\n",
    "\n",
    "ad_problem_test_x=ad_problem_data.iloc[:,0:58]\n",
    "ad_problem_test_y=ad_problem_data.iloc[:,58]\n",
    "\n",
    "ad_problem_test_url_x=pd.concat([ad_problem_data.iloc[:,0:27],ad_problem_data.iloc[:,49:58]],axis=1)\n",
    "ad_problem_test_html_x=ad_problem_data.iloc[:,27:49]\n",
    "\n",
    "print('lr_wa+_c_recall_combined:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,ad_problem_test_x,ad_problem_test_y,rfe_selector_lr_com)\n",
    "print('lr_wa+_c_recall-url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,ad_problem_test_url_x,ad_problem_test_y,rfe_selector_lr_url)\n",
    "print('lr_wa+_c_recall-html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,ad_problem_test_html_x,ad_problem_test_y,rfe_selector_lr_html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a7538",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pa_u attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41316a87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_pa_u_recall_com:\n",
      "recall 0.95\n",
      "lr_pa_u_recall_url:\n",
      "recall 0.94\n",
      "lr_pa_u_recall_html:\n",
      "recall 0.81\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phish_sub_test_x_ch=joblib.load(\"../data_folder/deltaphish/preprocessed/phish_sub_test_x_ch_pa_u.pkl\")\n",
    "\n",
    "phish_sub_test_url_x_ch=pd.concat([phish_sub_test_x_ch.iloc[:,0:27],phish_sub_test_x_ch.iloc[:,49:58]],axis=1)\n",
    "phish_sub_test_html_x_ch=phish_sub_test_x_ch.iloc[:,27:49]\n",
    "\n",
    "\n",
    "print('lr_pa_u_recall_com:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,phish_sub_test_x_ch,phish_sub_test_y,rfe_selector_lr_com)\n",
    "print('lr_pa_u_recall_url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,phish_sub_test_url_x_ch,phish_sub_test_y,rfe_selector_lr_url)\n",
    "print('lr_pa_u_recall_html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,phish_sub_test_html_x_ch,phish_sub_test_y,rfe_selector_lr_html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10066b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pa_r attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61a8a578",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_pa_r_recall_com:\n",
      "recall 0.24\n",
      "lr_pa_r_recall_url:\n",
      "recall 0.32\n",
      "lr_pa_r_recall_html:\n",
      "recall 0.04\n"
     ]
    }
   ],
   "source": [
    "phish_sub_test_x_ch=joblib.load(\"../data_folder/deltaphish/preprocessed/phish_sub_test_x_ch_pa_r.pkl\")\n",
    "\n",
    "phish_sub_test_url_x_ch=pd.concat([phish_sub_test_x_ch.iloc[:,0:27],phish_sub_test_x_ch.iloc[:,49:58]],axis=1)\n",
    "phish_sub_test_html_x_ch=phish_sub_test_x_ch.iloc[:,27:49]\n",
    "\n",
    "\n",
    "print('lr_pa_r_recall_com:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,phish_sub_test_x_ch,phish_sub_test_y,rfe_selector_lr_com)\n",
    "print('lr_pa_r_recall_url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,phish_sub_test_url_x_ch,phish_sub_test_y,rfe_selector_lr_url)\n",
    "print('lr_pa_r_recall_html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,phish_sub_test_html_x_ch,phish_sub_test_y,rfe_selector_lr_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd21098",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pa_c attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d15b7798",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_pa_c_recall_com:\n",
      "recall 0.76\n",
      "lr_pa_c_recall_url:\n",
      "recall 0.94\n",
      "lr_pa_c_recall_html:\n",
      "recall 0.44\n"
     ]
    }
   ],
   "source": [
    "phish_sub_test_x_ch=joblib.load(\"../data_folder/deltaphish/preprocessed/phish_sub_test_x_ch_pa_c.pkl\")\n",
    "\n",
    "phish_sub_test_url_x_ch=pd.concat([phish_sub_test_x_ch.iloc[:,0:27],phish_sub_test_x_ch.iloc[:,49:58]],axis=1)\n",
    "phish_sub_test_html_x_ch=phish_sub_test_x_ch.iloc[:,27:49]\n",
    "\n",
    "\n",
    "print('lr_pa_c_recall_com:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,phish_sub_test_x_ch,phish_sub_test_y,rfe_selector_lr_com)\n",
    "print('lr_pa_c_recall_url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,phish_sub_test_url_x_ch,phish_sub_test_y,rfe_selector_lr_url)\n",
    "print('lr_pa_c_recall_html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,phish_sub_test_html_x_ch,phish_sub_test_y,rfe_selector_lr_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77133199",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ma_u attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecda4123",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_ma_u_recall_com:\n",
      "recall 0.00\n",
      "lr_ma_u_recall_url:\n",
      "recall 0.00\n",
      "lr_ma_u_recall_html:\n",
      "recall 0.79\n"
     ]
    }
   ],
   "source": [
    "# phish_sub_test_x_ch: A copy of the original phish_sub_test_x DataFrame, which is then modified to include specific values for various URL features.\n",
    "# Various columns related to URL features are set to specific values\n",
    "phish_sub_test_x_ch=phish_sub_test_x.copy()\n",
    "phish_sub_test_x_ch['URL_length']=-1\n",
    "phish_sub_test_x_ch['URL_IP']=-1\n",
    "phish_sub_test_x_ch['URL_redirect']=-1\n",
    "phish_sub_test_x_ch['URL_shortener']=1\n",
    "phish_sub_test_x_ch['URL_subdomains']=-1\n",
    "phish_sub_test_x_ch['URL_at']=-1 \n",
    "phish_sub_test_x_ch['URL_dash']=-1  \n",
    "phish_sub_test_x_ch['URL_numberofCommonTerms']=-1 \n",
    "phish_sub_test_x_ch['URL_checkNumerical']=-1 \n",
    "phish_sub_test_x_ch['URL_checkPathExtend']=-1\n",
    "phish_sub_test_x_ch['URL_checkPunycode']=-1\n",
    "phish_sub_test_x_ch['URL_checkSensitiveWord']=0\n",
    "phish_sub_test_x_ch['URL_checkTLDinSub']=-1\n",
    "phish_sub_test_x_ch['URL_checkTLDinPath']=-1\n",
    "phish_sub_test_x_ch['URL_totalWordUrl']=0\n",
    " \n",
    "phish_sub_test_x_ch['URL_longestWordUrl']=0\n",
    "phish_sub_test_x_ch['URL_longestWordHost']=0\n",
    "phish_sub_test_x_ch['URL_longestWordPath']=0\n",
    "phish_sub_test_x_ch['URL_averageWordUrl']=1000\n",
    "phish_sub_test_x_ch['URL_averageWordHost']=0\n",
    "phish_sub_test_x_ch['URL_averageWordPath']=1000\n",
    "phish_sub_test_x_ch['REP_checkGI']=-1\n",
    "\n",
    "\n",
    "\n",
    "# phish_sub_test_url_x_ch: Stores the URL features by concatenating columns 0 to 26 and columns 49 to 57 from the phish_sub_test_x_ch DataFrame.\n",
    "# phish_sub_test_html_x_ch: Stores the HTML features extracted from columns 27 to 48 of the DataFrame.\n",
    "phish_sub_test_url_x_ch=pd.concat([phish_sub_test_x_ch.iloc[:,0:27],phish_sub_test_x_ch.iloc[:,49:58]],axis=1)\n",
    "phish_sub_test_html_x_ch=phish_sub_test_x_ch.iloc[:,27:49]\n",
    "\n",
    "print('lr_ma_u_recall_com:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,phish_sub_test_x_ch,phish_sub_test_y,rfe_selector_lr_com)\n",
    "print('lr_ma_u_recall_url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,phish_sub_test_url_x_ch,phish_sub_test_y,rfe_selector_lr_url)\n",
    "print('lr_ma_u_recall_html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,phish_sub_test_html_x_ch,phish_sub_test_y,rfe_selector_lr_html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75edb60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ma_r attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc94b496",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_ma_r_recall_com:\n",
      "recall 0.00\n",
      "lr_ma_r_recall_url:\n",
      "recall 0.32\n",
      "lr_ma_r_recall_html:\n",
      "recall 0.00\n"
     ]
    }
   ],
   "source": [
    "# phish_sub_test_x_ch: A copy of the original phish_sub_test_x DataFrame, which is then modified to include specific values for various HTML features.\n",
    "# Various columns related to HTML features are set to specific values\n",
    "phish_sub_test_x_ch=phish_sub_test_x.copy()\n",
    "\n",
    "phish_sub_test_x_ch['HTML_Objects']=-1\n",
    "phish_sub_test_x_ch['HTML_metaScripts']=-1\n",
    "phish_sub_test_x_ch['HTML_FrequentDomain']=-1\n",
    "phish_sub_test_x_ch['HTML_Commonpage']=1#0#1\n",
    "phish_sub_test_x_ch['HTML_CommonPageRatioinFooter']=1#1\n",
    "phish_sub_test_x_ch['HTML_popUp']=-1\n",
    "phish_sub_test_x_ch['HTML_RightClick']=-1\n",
    "phish_sub_test_x_ch['HTML_DomainwithCopyright']=-1\n",
    "phish_sub_test_x_ch['HTML_HiddenInfo_div']=-1\n",
    "phish_sub_test_x_ch['HTML_nullLinksinWeb']=1\n",
    "phish_sub_test_x_ch['HTML_nullLinksinFooter']=0#1\n",
    "phish_sub_test_x_ch['HTML_BrokenLink']=1\n",
    "phish_sub_test_x_ch['HTML_LoginForm']=-1\n",
    "phish_sub_test_x_ch['HTML_HiddenInfo_input']=-1\n",
    "phish_sub_test_x_ch['HTML_TitleUrlBrand']=-1\n",
    "phish_sub_test_x_ch['HTML_favicon']=-1\n",
    "phish_sub_test_x_ch['HTML_statusBarMod']=-1\n",
    "phish_sub_test_x_ch['HTML_css']=-1\n",
    "phish_sub_test_x_ch['HTML_anchors']=-1\n",
    "\n",
    "\n",
    "\n",
    "# phish_sub_test_url_x_ch: Stores the URL features by concatenating columns 0 to 26 and columns 49 to 57 from the phish_sub_test_x_ch DataFrame.\n",
    "# phish_sub_test_html_x_ch: Stores the HTML features extracted from columns 27 to 48 of the DataFrame.\n",
    "phish_sub_test_url_x_ch=pd.concat([phish_sub_test_x_ch.iloc[:,0:27],phish_sub_test_x_ch.iloc[:,49:58]],axis=1)\n",
    "phish_sub_test_html_x_ch=phish_sub_test_x_ch.iloc[:,27:49]\n",
    "\n",
    "\n",
    "print('lr_ma_r_recall_com:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,phish_sub_test_x_ch,phish_sub_test_y,rfe_selector_lr_com)\n",
    "print('lr_ma_r_recall_url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,phish_sub_test_url_x_ch,phish_sub_test_y,rfe_selector_lr_url)\n",
    "print('lr_ma_r_recall_html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,phish_sub_test_html_x_ch,phish_sub_test_y,rfe_selector_lr_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17260e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ma_c attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94db31e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_ma_c_recall_com:\n",
      "recall 0.00\n",
      "lr_ma_c_recall_url:\n",
      "recall 0.00\n",
      "lr_mc_c_recall_html:\n",
      "recall 0.00\n"
     ]
    }
   ],
   "source": [
    "phish_sub_test_x_ch=phish_sub_test_x.copy()\n",
    "phish_sub_test_x_ch['URL_length']=-1\n",
    "phish_sub_test_x_ch['URL_IP']=-1#single no change\n",
    "phish_sub_test_x_ch['URL_redirect']=-1#\n",
    "phish_sub_test_x_ch['URL_shortener']=1 #single no change\n",
    "phish_sub_test_x_ch['URL_subdomains']=-1\n",
    "phish_sub_test_x_ch['URL_at']=-1 \n",
    "phish_sub_test_x_ch['URL_dash']=-1  \n",
    "phish_sub_test_x_ch['URL_numberofCommonTerms']=-1 \n",
    "phish_sub_test_x_ch['URL_checkNumerical']=-1 #single no change\n",
    "phish_sub_test_x_ch['URL_checkPathExtend']=-1#single no change\n",
    "phish_sub_test_x_ch['URL_checkPunycode']=-1#single no change\n",
    "phish_sub_test_x_ch['URL_checkSensitiveWord']=0\n",
    "phish_sub_test_x_ch['URL_checkTLDinSub']=-1\n",
    "phish_sub_test_x_ch['URL_checkTLDinPath']=-1\n",
    "phish_sub_test_x_ch['URL_totalWordUrl']=0\n",
    "\n",
    "phish_sub_test_x_ch['URL_longestWordUrl']=0\n",
    "phish_sub_test_x_ch['URL_longestWordHost']=0 \n",
    "phish_sub_test_x_ch['URL_longestWordPath']=0\n",
    "phish_sub_test_x_ch['URL_averageWordUrl']=1000\n",
    "phish_sub_test_x_ch['URL_averageWordHost']=0\n",
    "phish_sub_test_x_ch['URL_averageWordPath']=1000\n",
    " \n",
    "phish_sub_test_x_ch['HTML_Objects']=-1\n",
    "phish_sub_test_x_ch['HTML_metaScripts']=-1\n",
    "phish_sub_test_x_ch['HTML_FrequentDomain']=-1\n",
    "phish_sub_test_x_ch['HTML_Commonpage']=1#0#1\n",
    "phish_sub_test_x_ch['HTML_CommonPageRatioinFooter']=1#1\n",
    " \n",
    "phish_sub_test_x_ch['HTML_popUp']=-1\n",
    "phish_sub_test_x_ch['HTML_RightClick']=-1\n",
    "phish_sub_test_x_ch['HTML_DomainwithCopyright']=-1\n",
    "phish_sub_test_x_ch['HTML_HiddenInfo_div']=-1\n",
    "phish_sub_test_x_ch['HTML_nullLinksinWeb']=1#1#0\n",
    "phish_sub_test_x_ch['HTML_nullLinksinFooter']=0#1\n",
    "phish_sub_test_x_ch['HTML_BrokenLink']=1\n",
    "phish_sub_test_x_ch['HTML_LoginForm']=-1\n",
    "phish_sub_test_x_ch['HTML_HiddenInfo_input']=-1\n",
    "phish_sub_test_x_ch['HTML_TitleUrlBrand']=-1\n",
    "phish_sub_test_x_ch['HTML_favicon']=-1\n",
    "phish_sub_test_x_ch['HTML_statusBarMod']=-1\n",
    "phish_sub_test_x_ch['HTML_css']=-1\n",
    "phish_sub_test_x_ch['HTML_anchors']=-1\n",
    "phish_sub_test_x_ch['REP_checkGI']=-1\n",
    "\n",
    "\n",
    "\n",
    "# phish_sub_test_url_x_ch: Stores the URL features by concatenating columns 0 to 26 and columns 49 to 57 from the phish_sub_test_x_ch DataFrame.\n",
    "# phish_sub_test_html_x_ch: Stores the HTML features extracted from columns 27 to 48 of the DataFrame.\n",
    "phish_sub_test_url_x_ch=pd.concat([phish_sub_test_x_ch.iloc[:,0:27],phish_sub_test_x_ch.iloc[:,49:58]],axis=1)\n",
    "phish_sub_test_html_x_ch=phish_sub_test_x_ch.iloc[:,27:49]\n",
    "\n",
    "\n",
    "print('lr_ma_c_recall_com:')\n",
    "base_sub_lr_recall_com=get_sub_base_rf_recall(model_lr_com,phish_sub_test_x_ch,phish_sub_test_y,rfe_selector_lr_com)\n",
    "print('lr_ma_c_recall_url:')\n",
    "base_sub_lr_recall_url=get_sub_base_rf_recall(model_lr_url,phish_sub_test_url_x_ch,phish_sub_test_y,rfe_selector_lr_url)\n",
    "print('lr_mc_c_recall_html:')\n",
    "base_sub_lr_recall_html=get_sub_base_rf_recall(model_lr_html,phish_sub_test_html_x_ch,phish_sub_test_y,rfe_selector_lr_html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
